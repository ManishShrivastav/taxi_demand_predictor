{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86f64c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import src.config as config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c96952e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_date=Timestamp('2025-12-31 15:00:00+0000', tz='UTC')\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime, timedelta, timezone\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "current_date = pd.to_datetime(datetime.now(timezone.utc)).floor('h')\n",
    "print(f\"{current_date=}\")\n",
    "\n",
    "# we fetch raw data for the last 28 days, to add redundancy to our data pipeline\n",
    "fetch_data_to = current_date\n",
    "fetch_data_from = current_date - timedelta(days=28)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "744ac135",
   "metadata": {},
   "source": [
    "We need to fetch the recent data. We don't have access to NYC Association Data Warehouse. So we are going to simulate a call to a data warehouse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c14b015",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data import load_raw_data\n",
    "\n",
    "def fetch_batch_raw_data(from_date: datetime, to_date: datetime) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Simulate production data by sampling historical data from 52 weeks ago (ie 1 year)\n",
    "    \"\"\"\n",
    "    from_date_ = from_date - timedelta(days=7*52)\n",
    "    to_date_ = to_date - timedelta(days=7*52)\n",
    "\n",
    "    # download 2 files from website\n",
    "    rides = load_raw_data(year=from_date_.year, months=from_date_.month)\n",
    "    rides['pickup_datetime'] = pd.to_datetime(rides['pickup_datetime']).dt.tz_localize(None)\n",
    "    rides = rides[rides.pickup_datetime >= from_date_.replace(tzinfo=None)]    \n",
    "    rides_2 = load_raw_data(year=to_date_.year, months=to_date_.month)\n",
    "    rides_2['pickup_datetime'] = pd.to_datetime(rides_2['pickup_datetime']).dt.tz_localize(None)\n",
    "    rides_2 = rides_2[rides_2.pickup_datetime < to_date_.replace(tzinfo=None)]\n",
    "\n",
    "    rides = pd.concat([rides, rides_2])\n",
    "\n",
    "    # Shift the data to pretend this is recent data\n",
    "    rides['pickup_datetime'] += timedelta(days=7*52)\n",
    "\n",
    "    rides.sort_values(by=['pickup_location_id', 'pickup_datetime'], inplace=True)\n",
    "\n",
    "    return rides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "329f2bb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File 2024-12 was already in local storage\n",
      "File 2025-01 was already in local storage\n"
     ]
    }
   ],
   "source": [
    "rides = fetch_batch_raw_data(from_date=fetch_data_from, to_date=fetch_data_to)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d25eb9e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 259/259 [00:01<00:00, 193.69it/s]\n"
     ]
    }
   ],
   "source": [
    "from src.data import transform_raw_data_into_ts_data\n",
    "ts_data = transform_raw_data_into_ts_data(rides)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "555db04d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HOME\\anaconda3\\envs\\pyimg\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-31 09:53:14,228 INFO: Initializing external client\n",
      "2025-12-31 09:53:14,229 INFO: Base URL: https://c.app.hopsworks.ai:443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "UserWarning: The installed hopsworks client version 4.6.0 may not be compatible with the connected Hopsworks backend version 4.2.2. \n",
      "To ensure compatibility please install the latest bug fix release matching the minor version of your backend (4.2) by running 'pip install hopsworks==4.2.*'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-31 09:53:15,160 INFO: Python Engine initialized.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/1329302\n"
     ]
    }
   ],
   "source": [
    "import hopsworks\n",
    "\n",
    "# Connect to the project \n",
    "project = hopsworks.login(\n",
    "    project=config.HOPSWORKS_PROJECT_NAME,\n",
    "    api_key_value=config.HOPSWORKS_API_KEY\n",
    ")\n",
    "\n",
    "# Connect to the feature store\n",
    "feature_store = project.get_feature_store()\n",
    "\n",
    "# Connect to the feature group\n",
    "feature_group = feature_store.get_or_create_feature_group(\n",
    "    name=config.FEATURE_GROUP_NAME,\n",
    "    version=config.FEATURE_GROUP_VERSION,\n",
    "    description = \"Time series data at hourly frequency\",\n",
    "    primary_key = ['pickup_location_id', 'pickup_hour'],\n",
    "    event_time='pickup_hour'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16ca41bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: (679098, 3)\n",
      "Data size in MB: 12.95\n",
      "Unique locations: 259\n",
      "Date range: 2025-12-03 15:00:00 to 2026-03-22 20:00:00\n"
     ]
    }
   ],
   "source": [
    "# Add this cell before the insert\n",
    "print(f\"Data shape: {ts_data.shape}\")\n",
    "print(f\"Data size in MB: {ts_data.memory_usage(deep=True).sum() / 1024 / 1024:.2f}\")\n",
    "print(f\"Unique locations: {ts_data['pickup_location_id'].nunique()}\")\n",
    "print(f\"Date range: {ts_data['pickup_hour'].min()} to {ts_data['pickup_hour'].max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e1ffc463",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Inserting 679098 rows to feature store...\n",
      "Date range: 2025-12-03 15:00:00 to 2026-03-22 20:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading Dataframe: 100.00% |██████████| Rows 679098/679098 | Elapsed Time: 00:35 | Remaining Time: 00:00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Data insert job submitted successfully\n",
      "Note: Data will be available in 1-2 minutes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "ts_data['pickup_location_id'] = ts_data['pickup_location_id'].astype('int64')\n",
    "\n",
    "print(f\"\\nInserting {len(ts_data)} rows to feature store...\")\n",
    "print(f\"Date range: {ts_data['pickup_hour'].min()} to {ts_data['pickup_hour'].max()}\")\n",
    "\n",
    "try:\n",
    "    feature_group.insert(\n",
    "        ts_data,\n",
    "        write_options={\n",
    "            \"wait_for_job\": False,\n",
    "            \"start_offline_materialization\": False  # CRITICAL: Skip materialization\n",
    "        }\n",
    "    )\n",
    "    print(\"✓ Data insert job submitted successfully\")\n",
    "    print(\"Note: Data will be available in 1-2 minutes\")\n",
    "except Exception as e:\n",
    "    print(f\"✗ Error: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f105865",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyimg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
