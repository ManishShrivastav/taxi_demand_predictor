{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "566b2dd3",
   "metadata": {},
   "source": [
    "In this case we will be training the model using date from the feature store (Hopsworks) and not the local `parquet` files and save the model to the Hopsworks model registry instead of local disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ea8944f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28676dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "import src.config as config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07e49446",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HOME\\anaconda3\\envs\\pyimg\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-31 14:33:28,638 INFO: Initializing external client\n",
      "2025-12-31 14:33:28,641 INFO: Base URL: https://c.app.hopsworks.ai:443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "UserWarning: The installed hopsworks client version 4.6.0 may not be compatible with the connected Hopsworks backend version 4.2.2. \n",
      "To ensure compatibility please install the latest bug fix release matching the minor version of your backend (4.2) by running 'pip install hopsworks==4.2.*'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-31 14:33:29,856 INFO: Python Engine initialized.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/1329302\n",
      "Using new versions: FG v3, FV v3\n",
      "\n",
      "Loading data for feature group...\n",
      "Downloading raw data from 2024 to 2025\n",
      "File 2024-01 was already in local storage\n",
      "File 2024-02 was already in local storage\n",
      "File 2024-03 was already in local storage\n",
      "File 2024-04 was already in local storage\n",
      "File 2024-05 was already in local storage\n",
      "File 2024-06 was already in local storage\n",
      "File 2024-07 was already in local storage\n",
      "File 2024-08 was already in local storage\n",
      "File 2024-09 was already in local storage\n",
      "File 2024-10 was already in local storage\n",
      "File 2024-11 was already in local storage\n",
      "File 2024-12 was already in local storage\n",
      "File 2025-01 was already in local storage\n",
      "File 2025-02 was already in local storage\n",
      "File 2025-03 was already in local storage\n",
      "File 2025-04 was already in local storage\n",
      "File 2025-05 was already in local storage\n",
      "File 2025-06 was already in local storage\n",
      "File 2025-07 was already in local storage\n",
      "File 2025-08 was already in local storage\n",
      "File 2025-09 was already in local storage\n",
      "File 2025-10 was already in local storage\n",
      "File 2025-11 was already in local storage\n",
      "Downloading file 2025-12\n",
      "2025-12 file is not available\n",
      "✓ Loaded 85586696 rides\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 263/263 [00:10<00:00, 25.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Transformed data shape: (4418400, 3)\n",
      "Columns: ['pickup_hour', 'rides', 'pickup_location_id']\n",
      "Data types:\n",
      "pickup_hour           datetime64[ns]\n",
      "rides                          int64\n",
      "pickup_location_id             int32\n",
      "dtype: object\n",
      "\n",
      "✓ Data types after conversion:\n",
      "pickup_hour           datetime64[ns]\n",
      "rides                          int64\n",
      "pickup_location_id             int64\n",
      "dtype: object\n",
      "\n",
      "Creating fresh feature group v3 with explicit schema...\n",
      "Inserting data into feature group...\n",
      "Feature Group created successfully, explore it at \n",
      "https://c.app.hopsworks.ai:443/p/1329302/fs/1317957/fg/1878604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading Dataframe: 100.00% |██████████| Rows 4418400/4418400 | Elapsed Time: 05:33 | Remaining Time: 00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching job: time_series_hourly_feature_group_3_offline_fg_materialization\n",
      "Job started successfully, you can follow the progress at \n",
      "https://c.app.hopsworks.ai:443/p/1329302/jobs/named/time_series_hourly_feature_group_3_offline_fg_materialization/executions\n",
      "2025-12-31 14:40:19,486 INFO: Waiting for execution to finish. Current state: INITIALIZING. Final status: UNDEFINED\n",
      "2025-12-31 14:40:22,575 INFO: Waiting for execution to finish. Current state: SUBMITTED. Final status: UNDEFINED\n",
      "2025-12-31 14:40:25,663 INFO: Waiting for execution to finish. Current state: RUNNING. Final status: UNDEFINED\n",
      "2025-12-31 14:44:42,656 INFO: Waiting for execution to finish. Current state: AGGREGATING_LOGS. Final status: SUCCEEDED\n",
      "2025-12-31 14:44:42,780 INFO: Waiting for log aggregation to finish.\n",
      "2025-12-31 14:45:00,720 INFO: Execution finished successfully.\n",
      "✓ Data inserted successfully!\n"
     ]
    }
   ],
   "source": [
    "import hopsworks\n",
    "from hsfs.feature import Feature\n",
    "\n",
    "# Connect to the project \n",
    "project = hopsworks.login(\n",
    "    project=config.HOPSWORKS_PROJECT_NAME,\n",
    "    api_key_value=config.HOPSWORKS_API_KEY\n",
    ")\n",
    "\n",
    "# Connect to the feature store\n",
    "feature_store = project.get_feature_store()\n",
    "\n",
    "# Use a NEW version to avoid the corrupted schema\n",
    "# Increment version to create fresh feature group\n",
    "FEATURE_GROUP_VERSION_NEW = 3\n",
    "FEATURE_VIEW_VERSION_NEW = 3\n",
    "\n",
    "print(f\"Using new versions: FG v{FEATURE_GROUP_VERSION_NEW}, FV v{FEATURE_VIEW_VERSION_NEW}\")\n",
    "\n",
    "# Load and transform data for the feature group\n",
    "print(\"\\nLoading data for feature group...\")\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "from src.data import load_raw_data, transform_raw_data_into_ts_data\n",
    "\n",
    "from_year = 2024\n",
    "to_year = datetime.now().year\n",
    "print(f\"Downloading raw data from {from_year} to {to_year}\")\n",
    "\n",
    "rides = pd.DataFrame()\n",
    "for year in range(from_year, to_year + 1):\n",
    "    rides_one_year = load_raw_data(year)\n",
    "    rides = pd.concat([rides, rides_one_year])\n",
    "\n",
    "print(f\"✓ Loaded {len(rides)} rides\")\n",
    "\n",
    "# Transform to time series data\n",
    "ts_data = transform_raw_data_into_ts_data(rides)\n",
    "print(f\"✓ Transformed data shape: {ts_data.shape}\")\n",
    "print(f\"Columns: {list(ts_data.columns)}\")\n",
    "print(f\"Data types:\\n{ts_data.dtypes}\")\n",
    "\n",
    "# Ensure correct data types before inserting\n",
    "ts_data['pickup_hour'] = pd.to_datetime(ts_data['pickup_hour'])\n",
    "ts_data['pickup_location_id'] = ts_data['pickup_location_id'].astype('int64')\n",
    "ts_data['rides'] = ts_data['rides'].astype('int64')\n",
    "\n",
    "print(f\"\\n✓ Data types after conversion:\\n{ts_data.dtypes}\")\n",
    "\n",
    "# Delete old feature view if exists (to avoid dependency issues)\n",
    "try:\n",
    "    feature_store.delete_feature_view(\n",
    "        name=config.FEATURE_VIEW_NAME,\n",
    "        version=FEATURE_VIEW_VERSION_NEW\n",
    "    )\n",
    "    print(f\"✓ Deleted existing feature view v{FEATURE_VIEW_VERSION_NEW}\")\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# Delete old feature group if exists\n",
    "try:\n",
    "    old_fg = feature_store.get_feature_group(\n",
    "        name=config.FEATURE_GROUP_NAME,\n",
    "        version=FEATURE_GROUP_VERSION_NEW\n",
    "    )\n",
    "    old_fg.delete()\n",
    "    print(f\"✓ Deleted existing feature group v{FEATURE_GROUP_VERSION_NEW}\")\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# Define explicit schema to avoid corruption bug\n",
    "schema = [\n",
    "    Feature(name=\"pickup_hour\", type=\"timestamp\"),\n",
    "    Feature(name=\"pickup_location_id\", type=\"bigint\"),\n",
    "    Feature(name=\"rides\", type=\"bigint\"),\n",
    "]\n",
    "\n",
    "# Create fresh feature group with EXPLICIT schema\n",
    "print(f\"\\nCreating fresh feature group v{FEATURE_GROUP_VERSION_NEW} with explicit schema...\")\n",
    "feature_group = feature_store.get_or_create_feature_group(\n",
    "    name=config.FEATURE_GROUP_NAME,\n",
    "    version=FEATURE_GROUP_VERSION_NEW,\n",
    "    description=\"Time-series data at hourly frequency\",\n",
    "    primary_key=['pickup_location_id', 'pickup_hour'],\n",
    "    event_time='pickup_hour',\n",
    "    features=schema  # Explicit schema definition\n",
    ")\n",
    "\n",
    "# Insert data\n",
    "print(\"Inserting data into feature group...\")\n",
    "feature_group.insert(ts_data, write_options={\"wait_for_job\": True})\n",
    "print(\"✓ Data inserted successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c86c8c80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inspecting feature group schema...\n",
      "Feature group name: time_series_hourly_feature_group\n",
      "Feature group version: 3\n",
      "\n",
      "Columns in feature group:\n",
      "  - pickup_hour: timestamp\n",
      "  - pickup_location_id: bigint\n",
      "  - rides: bigint\n",
      "\n",
      "Primary keys: ['pickup_hour', 'pickup_location_id']\n",
      "Event time: pickup_hour\n"
     ]
    }
   ],
   "source": [
    "print(\"Inspecting feature group schema...\")\n",
    "print(f\"Feature group name: {feature_group.name}\")\n",
    "print(f\"Feature group version: {feature_group.version}\")\n",
    "\n",
    "# Get schema from the feature group\n",
    "print(f\"\\nColumns in feature group:\")\n",
    "if hasattr(feature_group, 'schema'):\n",
    "    for feature in feature_group.schema:\n",
    "        print(f\"  - {feature.name}: {feature.type}\")\n",
    "else:\n",
    "    print(\"Schema not directly available, checking features...\")\n",
    "    # Alternative: check the feature_group structure\n",
    "    print(f\"Feature group attributes: {dir(feature_group)}\")\n",
    "\n",
    "print(f\"\\nPrimary keys: {feature_group.primary_key}\")\n",
    "print(f\"Event time: {feature_group.event_time}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c69298ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up feature view...\n",
      "ℹ No existing feature view v3 to delete\n",
      "Feature view created successfully, explore it at \n",
      "https://c.app.hopsworks.ai:443/p/1329302/fs/1317957/fv/time_series_hourly_feature_view/version/3\n",
      "✓ Feature view v3 created successfully\n",
      "✓ Feature view ready: <hsfs.feature_view.FeatureView object at 0x000001B0DD3C5290>\n"
     ]
    }
   ],
   "source": [
    "print(\"Setting up feature view...\")\n",
    "\n",
    "try:\n",
    "    # Delete any existing feature view first\n",
    "    try:\n",
    "        feature_store.delete_feature_view(\n",
    "            name=config.FEATURE_VIEW_NAME,\n",
    "            version=FEATURE_VIEW_VERSION_NEW\n",
    "        )\n",
    "        print(f'✓ Deleted existing feature view v{FEATURE_VIEW_VERSION_NEW}')\n",
    "    except:\n",
    "        print(f'ℹ No existing feature view v{FEATURE_VIEW_VERSION_NEW} to delete')\n",
    "    \n",
    "    # Create fresh feature view with new version\n",
    "    # Use select() with explicit column names instead of select_all()\n",
    "    query = feature_group.select([\"pickup_hour\", \"pickup_location_id\", \"rides\"])\n",
    "    feature_view = feature_store.create_feature_view(\n",
    "        name=config.FEATURE_VIEW_NAME,\n",
    "        version=FEATURE_VIEW_VERSION_NEW,\n",
    "        query=query\n",
    "    )\n",
    "    print(f\"✓ Feature view v{FEATURE_VIEW_VERSION_NEW} created successfully\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error creating feature view: {e}\")\n",
    "    # Try to get existing feature view as fallback\n",
    "    try:\n",
    "        feature_view = feature_store.get_feature_view(\n",
    "            name=config.FEATURE_VIEW_NAME,\n",
    "            version=FEATURE_VIEW_VERSION_NEW\n",
    "        )\n",
    "        print(f'✓ Using existing feature view v{FEATURE_VIEW_VERSION_NEW}')\n",
    "    except:\n",
    "        raise\n",
    "\n",
    "print(f\"✓ Feature view ready: {feature_view}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf3de4e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using local training data (Hopsworks Query Service bug workaround)...\n",
      "Note: Data was already inserted into feature store for inference pipeline\n",
      "✓ Training data ready! Shape: (4418400, 3)\n",
      "Columns: ['pickup_hour', 'rides', 'pickup_location_id']\n",
      "\n",
      "Data types:\n",
      "pickup_hour           datetime64[ns]\n",
      "rides                          int64\n",
      "pickup_location_id             int64\n",
      "dtype: object\n",
      "\n",
      "First few rows:\n",
      "          pickup_hour  rides  pickup_location_id\n",
      "0 2024-01-01 00:00:00     25                   4\n",
      "1 2024-01-01 01:00:00     29                   4\n",
      "2 2024-01-01 02:00:00     34                   4\n",
      "3 2024-01-01 03:00:00     31                   4\n",
      "4 2024-01-01 04:00:00     32                   4\n",
      "\n",
      "Data range: 2024-01-01 00:00:00 to 2025-11-30 23:00:00\n",
      "\n",
      "✓ Training data ready!\n"
     ]
    }
   ],
   "source": [
    "# WORKAROUND: Hopsworks Query Service has a bug with schema serialization\n",
    "# The server is storing column names as dictionary strings like \"{'name': 'pickup_hour', 'type': 'timestamp'}\"\n",
    "# Instead of fetching from feature store, we use the local ts_data that was already transformed\n",
    "\n",
    "print(\"Using local training data (Hopsworks Query Service bug workaround)...\")\n",
    "print(f\"Note: Data was already inserted into feature store for inference pipeline\")\n",
    "\n",
    "# ts_data is already available from cell 4 after transformation\n",
    "# Just verify it's ready\n",
    "if 'ts_data' in dir() and ts_data is not None and len(ts_data) > 0:\n",
    "    print(f\"✓ Training data ready! Shape: {ts_data.shape}\")\n",
    "    print(f\"Columns: {list(ts_data.columns)}\")\n",
    "    print(f\"\\nData types:\\n{ts_data.dtypes}\")\n",
    "    print(f\"\\nFirst few rows:\\n{ts_data.head()}\")\n",
    "    print(f\"\\nData range: {ts_data['pickup_hour'].min()} to {ts_data['pickup_hour'].max()}\")\n",
    "else:\n",
    "    raise Exception(\"ts_data not available - please run cell 4 first\")\n",
    "\n",
    "print(\"\\n✓ Training data ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521c2359",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyimg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
