{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cceeba7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "HOPSWORKS_PROJECT_NAME = 'nyc_taxiride_demand'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "450af61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from src.paths import PARENT_DIR\n",
    "\n",
    "# load key-value pairs from .env file located in the parent directory\n",
    "load_dotenv(PARENT_DIR / '.env')\n",
    "\n",
    "HOPSWORKS_API_KEY = os.environ['HOPSWORKS_API_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79096c6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading raw data from 2022 to 2025\n",
      "File 2022-01 was already in local storage\n",
      "File 2022-02 was already in local storage\n",
      "File 2022-03 was already in local storage\n",
      "File 2022-04 was already in local storage\n",
      "File 2022-05 was already in local storage\n",
      "File 2022-06 was already in local storage\n",
      "File 2022-07 was already in local storage\n",
      "File 2022-08 was already in local storage\n",
      "File 2022-09 was already in local storage\n",
      "File 2022-10 was already in local storage\n",
      "File 2022-11 was already in local storage\n",
      "File 2022-12 was already in local storage\n",
      "File 2023-01 was already in local storage\n",
      "File 2023-02 was already in local storage\n",
      "File 2023-03 was already in local storage\n",
      "File 2023-04 was already in local storage\n",
      "File 2023-05 was already in local storage\n",
      "File 2023-06 was already in local storage\n",
      "File 2023-07 was already in local storage\n",
      "File 2023-08 was already in local storage\n",
      "File 2023-09 was already in local storage\n",
      "File 2023-10 was already in local storage\n",
      "File 2023-11 was already in local storage\n",
      "File 2023-12 was already in local storage\n",
      "File 2024-01 was already in local storage\n",
      "File 2024-02 was already in local storage\n",
      "File 2024-03 was already in local storage\n",
      "File 2024-04 was already in local storage\n",
      "File 2024-05 was already in local storage\n",
      "File 2024-06 was already in local storage\n",
      "File 2024-07 was already in local storage\n",
      "File 2024-08 was already in local storage\n",
      "File 2024-09 was already in local storage\n",
      "File 2024-10 was already in local storage\n",
      "File 2024-11 was already in local storage\n",
      "File 2024-12 was already in local storage\n",
      "File 2025-01 was already in local storage\n",
      "File 2025-02 was already in local storage\n",
      "File 2025-03 was already in local storage\n",
      "File 2025-04 was already in local storage\n",
      "File 2025-05 was already in local storage\n",
      "File 2025-06 was already in local storage\n",
      "File 2025-07 was already in local storage\n",
      "File 2025-08 was already in local storage\n",
      "File 2025-09 was already in local storage\n",
      "File 2025-10 was already in local storage\n",
      "File 2025-11 was already in local storage\n",
      "Downloading file 2025-12\n",
      "2025-12 file is not available\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "from src.data import load_raw_data\n",
    "\n",
    "from_year = 2022\n",
    "to_year = datetime.now().year\n",
    "print(f\"Downloading raw data from {from_year} to {to_year}\")\n",
    "\n",
    "rides = pd.DataFrame()\n",
    "for year in range(from_year, to_year + 1):\n",
    "    # download data for the whole year\n",
    "    rides_one_year = load_raw_data(year)\n",
    "\n",
    "    # append rows\n",
    "    rides = pd.concat([rides, rides_one_year])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53a1989e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(rides) = 163550837\n"
     ]
    }
   ],
   "source": [
    "print(f\"{len(rides) = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fca168c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 263/263 [00:21<00:00, 12.51it/s]\n"
     ]
    }
   ],
   "source": [
    "from src.data import transform_raw_data_into_ts_data\n",
    "\n",
    "ts_data = transform_raw_data_into_ts_data(rides)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ff0aa2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HOME\\anaconda3\\envs\\pyimg\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import hopsworks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dfba7af6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-31 09:24:55,888 INFO: Initializing external client\n",
      "2025-12-31 09:24:55,890 INFO: Base URL: https://c.app.hopsworks.ai:443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "UserWarning: The installed hopsworks client version 4.6.0 may not be compatible with the connected Hopsworks backend version 4.2.2. \n",
      "To ensure compatibility please install the latest bug fix release matching the minor version of your backend (4.2) by running 'pip install hopsworks==4.2.*'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-31 09:24:57,265 INFO: Python Engine initialized.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/1329302\n"
     ]
    }
   ],
   "source": [
    "project = hopsworks.login(\n",
    "    project=HOPSWORKS_PROJECT_NAME,\n",
    "    api_key_value=HOPSWORKS_API_KEY\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe63c667",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_store = project.get_feature_store()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "27399619",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To save data into feature store use feature groups api to write data.\n",
    "# This needs feature group name and version\n",
    "FEATURE_GROUP_NAME = 'time_series_hourly_feature_group'\n",
    "FEATURE_GROUP_VERSION = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "87371fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create feature group\n",
    "feature_group = feature_store.get_or_create_feature_group(\n",
    "    name=FEATURE_GROUP_NAME,\n",
    "    version=FEATURE_GROUP_VERSION,\n",
    "    description=\"Time-series data at hourly frequency\",\n",
    "    primary_key=['pickup_location_id', 'pickup_hour'], # A unique identifier for each row in the data (location_id and hour)\n",
    "    event_time='pickup_hour' # This is the timestamp behind those events\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "db32c5ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: (9026160, 3)\n",
      "\n",
      "Data types:\n",
      "pickup_hour           datetime64[ns]\n",
      "rides                          int64\n",
      "pickup_location_id             int64\n",
      "dtype: object\n",
      "\n",
      "First few rows:\n",
      "          pickup_hour  rides  pickup_location_id\n",
      "0 2022-01-01 00:00:00     11                   4\n",
      "1 2022-01-01 01:00:00     15                   4\n",
      "2 2022-01-01 02:00:00     26                   4\n",
      "3 2022-01-01 03:00:00      8                   4\n",
      "4 2022-01-01 04:00:00      9                   4\n",
      "\n",
      "Missing values:\n",
      "pickup_hour           0\n",
      "rides                 0\n",
      "pickup_location_id    0\n",
      "dtype: int64\n",
      "\n",
      "Check for duplicates in primary key:\n",
      "Duplicate primary keys: 0\n",
      "\n",
      "Inserting data to feature store...\n",
      "Feature Group created successfully, explore it at \n",
      "https://c.app.hopsworks.ai:443/p/1329302/fs/1317957/fg/1880534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading Dataframe: 100.00% |██████████| Rows 9026160/9026160 | Elapsed Time: 09:00 | Remaining Time: 00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching job: time_series_hourly_feature_group_1_offline_fg_materialization\n",
      "Job started successfully, you can follow the progress at \n",
      "https://c.app.hopsworks.ai:443/p/1329302/jobs/named/time_series_hourly_feature_group_1_offline_fg_materialization/executions\n",
      "Data insert job submitted successfully\n"
     ]
    }
   ],
   "source": [
    "# Validate data before inserting\n",
    "print(\"Data shape:\", ts_data.shape)\n",
    "print(\"\\nData types:\")\n",
    "print(ts_data.dtypes)\n",
    "print(\"\\nFirst few rows:\")\n",
    "print(ts_data.head())\n",
    "print(\"\\nMissing values:\")\n",
    "print(ts_data.isnull().sum())\n",
    "print(\"\\nCheck for duplicates in primary key:\")\n",
    "duplicates = ts_data.groupby(['pickup_location_id', 'pickup_hour']).size()\n",
    "num_duplicates = (duplicates > 1).sum()\n",
    "print(f\"Duplicate primary keys: {num_duplicates}\")\n",
    "if num_duplicates > 0:\n",
    "    print(\"Duplicate rows:\")\n",
    "    print(duplicates[duplicates > 1].head(10))\n",
    "\n",
    "# save data to the feature store\n",
    "print(\"\\nInserting data to feature store...\")\n",
    "feature_group.insert(ts_data, \n",
    "                     write_options={\"wait_for_job\": False}) # Don't wait for this job to finalize.\n",
    "print(\"Data insert job submitted successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6107186",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyimg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
